{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNY/LswRc4aFLOfDKWYgWDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadgh76/Federated-Learning/blob/main/Non_IID_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "Nno7_iuyLP3B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b6_HeV1DK8tk"
      },
      "outputs": [],
      "source": [
        "def attack(row):\n",
        "    if row['attack'] == 'normal':\n",
        "        return 'normal'\n",
        "    elif row['attack'] in ['port-Sweep', 'ip-Sweep', 'nmap', 'satan', 'saint', 'mscan']:\n",
        "        return 'Probing'\n",
        "    elif row['attack'] in ['neptune', 'smurf', 'pod', 'teardrop', 'land', 'back', 'apache2',\n",
        "                          'udpstorm', 'processtable', ',mail-Bomb']:\n",
        "        return 'Dos'\n",
        "    elif row['attack'] in ['buffer-Overflow', 'load-Module', 'perl', 'rootkit', 'xterm',\n",
        "                          'ps', 'sqlattack']:\n",
        "        return 'U2R'\n",
        "    else:\n",
        "        return 'R2L'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import copy\n",
        "\n",
        "# import csv\n",
        "# import random\n",
        "# import time\n",
        "# import pandas as pd\n",
        "# from sklearn.model_selection import KFold\n",
        "# import random\n",
        "# # Importing necessary libraries for preprocessing and modeling\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import warnings\n",
        "# from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout\n",
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def plot_class_distribution(data):\n",
        "#     attack_counts = data.sum(axis=0)  # Sum along the rows to get total counts for each attack type\n",
        "#     attack_counts.plot(kind='bar')\n",
        "#     plt.title('Class Distribution')\n",
        "#     plt.xlabel('Attack Type')\n",
        "#     plt.ylabel('Count')\n",
        "#     plt.show()\n",
        "\n",
        "# # Importing necessary libraries for preprocessing and modeling\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import warnings\n",
        "# from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout\n",
        "\n",
        "# # Function to preprocess the data\n",
        "# def preprocess(train_path, test_path):\n",
        "\n",
        "#     Train_data = pd.read_csv(train_path)\n",
        "#     Test_data = pd.read_csv(test_path)\n",
        "#     Train_data.drop('20',axis=1,inplace=True)\n",
        "#     Test_data.drop('21',axis=1,inplace=True)\n",
        "\n",
        "#     # Renaming columns\n",
        "#     columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "#                 ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "#                 ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "#                 ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "#                 ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "#                 ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "#                 ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "#                 ,'dst_host_srv_rerror_rate','attack'])\n",
        "\n",
        "#     Train_data.columns = columns\n",
        "#     Test_data.columns = columns\n",
        "\n",
        "#     Train_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "#     Test_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "\n",
        "#     Train_data['attack']=Train_data.apply(attack,axis=1)\n",
        "#     Test_data['attack']=Test_data.apply(attack,axis=1)\n",
        "\n",
        "#     # Label encoding categorical features\n",
        "#     ob=Train_data.select_dtypes(['object']).columns\n",
        "#     from sklearn.preprocessing import LabelEncoder\n",
        "#     protocol_type_le = LabelEncoder()\n",
        "#     service_le = LabelEncoder()\n",
        "#     flag_le = LabelEncoder()\n",
        "\n",
        "#     Train_data['protocol_type'] = protocol_type_le.fit_transform(Train_data['protocol_type'])\n",
        "#     Train_data['service'] = service_le.fit_transform(Train_data['service'])\n",
        "#     Train_data['flag'] = flag_le.fit_transform(Train_data['flag'])\n",
        "\n",
        "#     Test_data['protocol_type'] = protocol_type_le.transform(Test_data['protocol_type'])\n",
        "#     Test_data['service'] = service_le.transform(Test_data['service'])\n",
        "#     Test_data['flag'] = flag_le.transform(Test_data['flag'])\n",
        "\n",
        "#     # One-hot encoding the target variable\n",
        "#     Train_data = pd.get_dummies(Train_data, columns=['attack'])\n",
        "#     Test_data= pd.get_dummies(Test_data, columns=['attack'])\n",
        "\n",
        "#     # Selecting important features\n",
        "#     ImportantFeatures=Train_data.columns[0:40]\n",
        "#     x_train = Train_data[ImportantFeatures].values\n",
        "#     y_train = Train_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "#     x_test = Test_data[ImportantFeatures].values\n",
        "#     y_test = Test_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "#     # Scaling features\n",
        "#     ro_scaler = RobustScaler()\n",
        "#     x_train = ro_scaler.fit_transform(x_train)\n",
        "#     x_test = ro_scaler.transform(x_test)\n",
        "\n",
        "#     ros_scaler = StandardScaler()\n",
        "#     x_train = ros_scaler.fit_transform(x_train)\n",
        "#     x_test = ros_scaler.transform(x_test)\n",
        "#     return (x_train, y_train), (x_test, y_test)"
      ],
      "metadata": {
        "id": "Vf5PtLfXK9qt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_path=\"/content/KDDTrain+.txt\"\n",
        "# test_path =\"/content/KDDTest+.txt\"\n",
        "# # Preprocess the data\n",
        "# (x_train, y_train), (x_test, y_test) = preprocess(train_path, test_path)\n",
        "\n",
        "# plot_class_distribution(pd.DataFrame(y_train))\n",
        "# plot_class_distribution(pd.DataFrame(y_test))\n"
      ],
      "metadata": {
        "id": "ybflB13TLhmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
        "\n",
        "# def preprocess(train_path, test_path):\n",
        "#     # Read train and test data\n",
        "#     Train_data = pd.read_csv(train_path)\n",
        "#     Test_data = pd.read_csv(test_path)\n",
        "\n",
        "# # Train_data = pd.read_csv(\"/content/KDDTrain+.txt\")\n",
        "# # Test_data = pd.read_csv(\"/content/KDDTest+.txt\")\n",
        "\n",
        "#     Train_data.drop('20',axis=1,inplace=True)\n",
        "#     Test_data.drop('21',axis=1,inplace=True)\n",
        "\n",
        "#     columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "#                 ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "#                 ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "#                 ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "#                 ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "#                 ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "#                 ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "#                 ,'dst_host_srv_rerror_rate','attack'])\n",
        "\n",
        "\n",
        "#     Train_data.columns = columns\n",
        "#     Test_data.columns = columns\n",
        "\n",
        "#     Train_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "#     Test_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "\n",
        "#     Train_data['attack']=Train_data.apply(attack,axis=1)\n",
        "#     Test_data['attack']=Test_data.apply(attack,axis=1)\n",
        "\n",
        "#     ob=Train_data.select_dtypes(['object']).columns\n",
        "#     from sklearn.preprocessing import LabelEncoder\n",
        "#     protocol_type_le = LabelEncoder()\n",
        "#     service_le = LabelEncoder()\n",
        "#     flag_le = LabelEncoder()\n",
        "\n",
        "#     Train_data['protocol_type'] = protocol_type_le.fit_transform(Train_data['protocol_type'])\n",
        "#     Train_data['service'] = service_le.fit_transform(Train_data['service'])\n",
        "#     Train_data['flag'] = flag_le.fit_transform(Train_data['flag'])\n",
        "\n",
        "#     Test_data['protocol_type'] = protocol_type_le.transform(Test_data['protocol_type'])\n",
        "#     Test_data['service'] = service_le.transform(Test_data['service'])\n",
        "#     Test_data['flag'] = flag_le.transform(Test_data['flag'])\n",
        "\n",
        "#     Train_data = pd.get_dummies(Train_data, columns=['attack'])\n",
        "#     Test_data= pd.get_dummies(Test_data, columns=['attack'])\n",
        "\n",
        "#     ImportantFeatures=Train_data.columns[0:40]\n",
        "#     x_train = Train_data[ImportantFeatures].values\n",
        "#     y_train = Train_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "#     x_test = Test_data[ImportantFeatures].values\n",
        "#     y_test = Test_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "#     ro_scaler = RobustScaler()\n",
        "#     x_train = ro_scaler.fit_transform(x_train)\n",
        "#     x_test = ro_scaler.transform(x_test)\n",
        "\n",
        "#     ros_scaler = StandardScaler()\n",
        "#     x_train = ros_scaler.fit_transform(x_train)\n",
        "#     x_test = ros_scaler.transform(x_test)\n",
        "\n",
        "\n",
        "#     return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "# # Example usage\n",
        "# train_path = \"/content/KDDTrain+.txt\"\n",
        "# test_path = \"/content/KDDTest+.txt\"\n",
        "# (x_train, y_train), (x_test, y_test) = preprocess(train_path, test_path)\n",
        "\n",
        "# print(\"x_train shape:\", x_train.shape)\n",
        "# print(\"y_train shape:\", y_train.shape)\n",
        "# print(\"x_test shape:\", x_test.shape)\n",
        "# print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "zPIE9oPi4xGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
        "\n",
        "def preprocess(train_path, test_path):\n",
        "    # Read train and test data\n",
        "    Train_data = pd.read_csv(train_path)\n",
        "    Test_data = pd.read_csv(test_path)\n",
        "\n",
        "# Train_data = pd.read_csv(\"/content/KDDTrain+.txt\")\n",
        "# Test_data = pd.read_csv(\"/content/KDDTest+.txt\")\n",
        "\n",
        "    Train_data.drop('20',axis=1,inplace=True)\n",
        "    Test_data.drop('21',axis=1,inplace=True)\n",
        "\n",
        "    columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent'\n",
        "                ,'hot','num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root'\n",
        "                ,'num_file_creations','num_shells','num_access_files','num_outbound_cmds','is_host_login'\n",
        "                ,'is_guest_login','count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate'\n",
        "                ,'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'\n",
        "                ,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate'\n",
        "                ,'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate','dst_host_rerror_rate'\n",
        "                ,'dst_host_srv_rerror_rate','attack'])\n",
        "\n",
        "\n",
        "    Train_data.columns = columns\n",
        "    Test_data.columns = columns\n",
        "\n",
        "    Train_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "    Test_data.drop('num_outbound_cmds',axis=1,inplace=True)\n",
        "\n",
        "    Train_data['attack']=Train_data.apply(attack,axis=1)\n",
        "    Test_data['attack']=Test_data.apply(attack,axis=1)\n",
        "\n",
        "    ob=Train_data.select_dtypes(['object']).columns\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    protocol_type_le = LabelEncoder()\n",
        "    service_le = LabelEncoder()\n",
        "    flag_le = LabelEncoder()\n",
        "\n",
        "    Train_data['protocol_type'] = protocol_type_le.fit_transform(Train_data['protocol_type'])\n",
        "    Train_data['service'] = service_le.fit_transform(Train_data['service'])\n",
        "    Train_data['flag'] = flag_le.fit_transform(Train_data['flag'])\n",
        "\n",
        "    Test_data['protocol_type'] = protocol_type_le.transform(Test_data['protocol_type'])\n",
        "    Test_data['service'] = service_le.transform(Test_data['service'])\n",
        "    Test_data['flag'] = flag_le.transform(Test_data['flag'])\n",
        "\n",
        "    Train_data = pd.get_dummies(Train_data, columns=['attack'])\n",
        "    Test_data= pd.get_dummies(Test_data, columns=['attack'])\n",
        "\n",
        "    ImportantFeatures=Train_data.columns[0:40]\n",
        "    x_train = Train_data[ImportantFeatures].values\n",
        "    y_train = Train_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "    x_test = Test_data[ImportantFeatures].values\n",
        "    y_test = Test_data[['attack_normal', 'attack_Probing', 'attack_Dos', 'attack_U2R', 'attack_R2L']].values\n",
        "\n",
        "    ro_scaler = RobustScaler()\n",
        "    x_train = ro_scaler.fit_transform(x_train)\n",
        "    x_test = ro_scaler.transform(x_test)\n",
        "\n",
        "    ros_scaler = StandardScaler()\n",
        "    x_train = ros_scaler.fit_transform(x_train)\n",
        "    x_test = ros_scaler.transform(x_test)\n",
        "\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "def create_non_iid_data(x_train, y_train, num_clients):\n",
        "    client_data = []\n",
        "    kf = KFold(n_splits=num_clients * 2, shuffle=True, random_state=42)  # Use num_clients * 2 for more folds\n",
        "    folds = list(kf.split(x_train))\n",
        "\n",
        "    for i, (fold_train_index, _) in enumerate(folds):\n",
        "        # print(\"Fold {} indices before shuffling: {}\".format(i, fold_train_index))\n",
        "        np.random.shuffle(fold_train_index)\n",
        "        # print(\"Fold {} indices after shuffling: {}\".format(i, fold_train_index))\n",
        "        client_x_train, client_y_train = x_train[fold_train_index], y_train[fold_train_index]\n",
        "        client_data.append((client_x_train, client_y_train))\n",
        "\n",
        "    return client_data\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "train_path=\"/content/KDDTrain+.txt\"\n",
        "test_path =\"/content/KDDTest+.txt\"\n",
        "(x_train, y_train), (x_test, y_test) = preprocess(train_path, test_path)\n",
        "x_train.shape\n",
        "x_test.shape\n",
        "y_train.shape\n",
        "y_test.shape\n",
        "\n",
        "num_clients = 10  # specify the number of clients\n",
        "client_data = create_non_iid_data(x_train, y_train, num_clients)\n"
      ],
      "metadata": {
        "id": "CRodHig3euWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example client data\n",
        "# client_data = [1, 2, 1, 3, 2, 4, 1, 3, 5, 4, 1, 2, 3, 4, 5]\n",
        "\n",
        "# Number of clients\n",
        "num_clients = 10\n",
        "\n",
        "# Count the occurrences of each client ID\n",
        "client_counts = np.zeros(num_clients)\n",
        "for client_id in client_data:\n",
        "    client_counts[client_id - 1] += 1\n",
        "\n",
        "# Create bar plot\n",
        "plt.bar(np.arange(1, num_clients + 1), client_counts, align='center')\n",
        "plt.xlabel('Client ID')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Distribution of Client Data')\n",
        "plt.xticks(np.arange(1, num_clients + 1))\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8v3xdJzGrB3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}