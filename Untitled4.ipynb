{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYzFh2aog68AueFnmoJgfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadgh76/Federated-Learning/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NElMKSyMBMab",
        "outputId": "d0bfa11c-7bcc-4583-f0b5-f6cd97a39ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protocol_type\n",
            "service\n",
            "flag\n",
            "labels\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'dfkjsdjfjklfsd'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "import types\n",
        "from numpy.lib.arraysetops import unique\n",
        "import collections\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "trn = pd.read_csv(\"/content/kdd_train.csv\")\n",
        "trn.isnull().sum()\n",
        "trn.nunique()\n",
        "types = trn[\"labels\"].unique()\n",
        "types = types[1:]\n",
        "trn[\"labels\"].replace(to_replace=types,value=\"attacking\",inplace = True)\n",
        "c = len(trn.select_dtypes(include=[\"number\"]).columns)\n",
        "\n",
        "cols = ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
        "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "       'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
        "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
        "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
        "       'dst_host_srv_rerror_rate']\n",
        "\n",
        "for col in trn.select_dtypes(include=[\"object\"]):\n",
        "    print(col)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ['protocol_type','service','flag','labels']\n",
        "for i in cols:\n",
        "    en = LabelEncoder()\n",
        "    trn[i] = en.fit_transform(trn[i])\n",
        "\n",
        "\n",
        "corr_matrix = trn.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "trn.drop(to_drop, axis=1, inplace=True)\n",
        "\n",
        "trn.head(10)\n",
        "X_trn = trn.drop(['labels'] , axis = 1).values\n",
        "Y_trn = trn['labels'].values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_trn = scaler.fit_transform(X_trn)\n",
        "\n",
        "\n",
        "tff.federated_computation(lambda: \"dfkjsdjfjklfsd\")()\n",
        "\n",
        "# trn = tf.convert_to_tensor(trn)\n",
        "# trn = tf.data.Dataset.from_tensors(trn)\n",
        "# train_sample = tf.convert_to_tensor(X_trn)\n",
        "# test_sample =  tf.convert_to_tensor(Y_trn)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_datasets(trn: pd.DataFrame,\n",
        "                       batch_size: int = 1,\n",
        "                       max_examples_per_user: Optional[int] = None,\n",
        "                       max_clients: Optional[int] = None) -> List[tf.data.Dataset]:\n",
        "\n",
        "\n",
        "  num_users = len(set(trn.duration))\n",
        "  if max_clients is not None:\n",
        "    num_users = min(num_users, max_clients)\n",
        "\n",
        "  def rating_batch_map_fn(trn_batch):\n",
        "    return collections.OrderedDict([\n",
        "        (\"x\", tf.cast(trn_batch[:, 0:35], tf.float32)),\n",
        "        (\"y\", tf.cast(trn_batch[:, 35:36], tf.int32))\n",
        "    ])\n",
        "\n",
        "  tf_datasets = []\n",
        "  for user_id in range(num_users):\n",
        "\n",
        "    tf_dataset = tf.data.Dataset.from_tensor_slices(trn)\n",
        "\n",
        "    # Define preprocessing operations.\n",
        "    tf_dataset = tf_dataset.take(max_examples_per_user).shuffle(\n",
        "        buffer_size=max_examples_per_user, seed=42).batch(batch_size).map(\n",
        "        rating_batch_map_fn,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    tf_datasets.append(tf_dataset)\n",
        "\n",
        "  return tf_datasets\n",
        "\n",
        "\n",
        "def split_tf_datasets(\n",
        "    tf_datasets: List[tf.data.Dataset],\n",
        "    train_fraction: float = 0.8,\n",
        "    val_fraction: float = 0.1,\n",
        ") -> Tuple[List[tf.data.Dataset], List[tf.data.Dataset], List[tf.data.Dataset]]:\n",
        "  np.random.seed(42)\n",
        "  np.random.shuffle(tf_datasets)\n",
        "\n",
        "  train_idx = int(len(tf_datasets) * train_fraction)\n",
        "  val_idx = int(len(tf_datasets) * (train_fraction + val_fraction))\n",
        "  return (tf_datasets[:train_idx], tf_datasets[train_idx:val_idx],\n",
        "          tf_datasets[val_idx:])"
      ],
      "metadata": {
        "id": "g4KnLZ55Bcb7"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_datasets = create_tf_datasets(\n",
        "    trn=trn,\n",
        "    batch_size=50,\n",
        "    max_examples_per_user=30,\n",
        "    max_clients=5)\n",
        "\n",
        "tf_train_datasets, tf_val_datasets, tf_test_datasets = split_tf_datasets(\n",
        "    tf_datasets,\n",
        "    train_fraction=0.7,\n",
        "    val_fraction=0.1)"
      ],
      "metadata": {
        "id": "_jmjje-YHlyw"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(tf_train_datasets[1])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Q2lMDGIDUL",
        "outputId": "eff0cfed-7385-4bc6-89e9-7d103a972ca0"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('x', <tf.Tensor: shape=(30, 35), dtype=float32, numpy=\n",
            "array([[0.00e+00, 1.00e+00, 3.80e+01, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
            "       [5.07e+02, 1.00e+00, 6.00e+01, ..., 0.00e+00, 0.00e+00, 2.00e-02],\n",
            "       [0.00e+00, 1.00e+00, 4.90e+01, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
            "       ...,\n",
            "       [0.00e+00, 1.00e+00, 2.40e+01, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
            "       [0.00e+00, 1.00e+00, 4.90e+01, ..., 0.00e+00, 0.00e+00, 0.00e+00],\n",
            "       [0.00e+00, 0.00e+00, 1.40e+01, ..., 1.00e+00, 1.00e+00, 0.00e+00]],\n",
            "      dtype=float32)>), ('y', <tf.Tensor: shape=(30, 1), dtype=int32, numpy=\n",
            "array([[0],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [1],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0],\n",
            "       [0],\n",
            "       [1],\n",
            "       [0],\n",
            "       [0]], dtype=int32)>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MnistVariables = collections.namedtuple(\n",
        "    'MnistVariables', 'weights bias num_examples loss_sum accuracy_sum')"
      ],
      "metadata": {
        "id": "WjbgutiuK_XG"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mnist_variables():\n",
        "  return MnistVariables(\n",
        "      weights=tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(35, 1)),\n",
        "          name='weights',\n",
        "          trainable=True),\n",
        "      bias=tf.Variable(\n",
        "          lambda: tf.zeros(dtype=tf.float32, shape=(2)),\n",
        "          name='bias',\n",
        "          trainable=True),\n",
        "      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),\n",
        "      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),\n",
        "      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False))"
      ],
      "metadata": {
        "id": "AJk385IdLADO"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_on_batch(variables, x):\n",
        "  return tf.nn.softmax(tf.matmul(x, variables.weights) + variables.bias)\n",
        "\n",
        "def mnist_forward_pass(variables, batch):\n",
        "  y = predict_on_batch(variables, batch['x'])\n",
        "  predictions = tf.cast(tf.argmax(y, 1), tf.int32)\n",
        "\n",
        "  flat_labels = tf.reshape(batch['y'], [-1])\n",
        "  loss = -tf.reduce_mean(\n",
        "      tf.reduce_sum(tf.one_hot(flat_labels, 2) * tf.math.log(y), axis=[1]))\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(tf.equal(predictions, flat_labels), tf.float32))\n",
        "\n",
        "  num_examples = tf.cast(tf.size(batch['y']), tf.float32)\n",
        "\n",
        "  variables.num_examples.assign_add(num_examples)\n",
        "  variables.loss_sum.assign_add(loss * num_examples)\n",
        "  variables.accuracy_sum.assign_add(accuracy * num_examples)\n",
        "\n",
        "  return loss, predictions"
      ],
      "metadata": {
        "id": "jhPhT-OoLQr-"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_local_unfinalized_metrics(variables):\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=[variables.num_examples],\n",
        "      loss=[variables.loss_sum, variables.num_examples],\n",
        "      accuracy=[variables.accuracy_sum, variables.num_examples])"
      ],
      "metadata": {
        "id": "DhPrfy6SLogj"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metric_finalizers():\n",
        "  return collections.OrderedDict(\n",
        "      num_examples=tf.function(func=lambda x: x[0]),\n",
        "      loss=tf.function(func=lambda x: x[0] / x[1]),\n",
        "      accuracy=tf.function(func=lambda x: x[0] / x[1]))"
      ],
      "metadata": {
        "id": "B1-zXtb7LsgQ"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections.abc import Callable\n",
        "\n",
        "class MnistModel(tff.learning.models.VariableModel):\n",
        "\n",
        "  def __init__(self):\n",
        "    self._variables = create_mnist_variables()\n",
        "\n",
        "  @property\n",
        "  def trainable_variables(self):\n",
        "    return [self._variables.weights, self._variables.bias]\n",
        "\n",
        "  @property\n",
        "  def non_trainable_variables(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def local_variables(self):\n",
        "    return [\n",
        "        self._variables.num_examples, self._variables.loss_sum,\n",
        "        self._variables.accuracy_sum\n",
        "    ]\n",
        "\n",
        "  @property\n",
        "  def input_spec(self):\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.TensorSpec([None, 35], tf.float32),\n",
        "        y=tf.TensorSpec([None, 1], tf.int32))\n",
        "\n",
        "  @tf.function\n",
        "  def predict_on_batch(self, x, training=True):\n",
        "    del training\n",
        "    return predict_on_batch(self._variables, x)\n",
        "\n",
        "  @tf.function\n",
        "  def forward_pass(self, batch, training=True):\n",
        "    del training\n",
        "    loss, predictions = mnist_forward_pass(self._variables, batch)\n",
        "    num_exmaples = tf.shape(batch['x'])[0]\n",
        "    return tff.learning.models.BatchOutput(\n",
        "        loss=loss, predictions=predictions, num_examples=num_exmaples)\n",
        "\n",
        "  @tf.function\n",
        "  def report_local_unfinalized_metrics(\n",
        "      self) -> collections.OrderedDict[str, list[tf.Tensor]]:\n",
        "    \"\"\"Creates an `OrderedDict` of metric names to unfinalized values.\"\"\"\n",
        "    return get_local_unfinalized_metrics(self._variables)\n",
        "\n",
        "  def metric_finalizers(\n",
        "      self) -> collections.OrderedDict[str, Callable[[list[tf.Tensor]], tf.Tensor]]:\n",
        "    \"\"\"Creates an `OrderedDict` of metric names to finalizers.\"\"\"\n",
        "    return get_metric_finalizers()\n",
        "\n",
        "  @tf.function\n",
        "  def reset_metrics(self):\n",
        "    \"\"\"Resets metrics variables to initial value.\"\"\"\n",
        "    for var in self.local_variables:\n",
        "      var.assign(tf.zeros_like(var))"
      ],
      "metadata": {
        "id": "cl_lG-j4LxbN"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "\n",
        "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "    MnistModel,\n",
        "    client_optimizer_fn=lambda:tf.keras.optimizers.SGD(learning_rate=0.02))"
      ],
      "metadata": {
        "id": "WW0k8pqDMuWj"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_state = training_process.initialize()"
      ],
      "metadata": {
        "id": "tbZr7ihJOVup"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for round_num in range(2, 11):\n",
        "  result = training_process.next(train_state, tf_train_datasets)\n",
        "  train_state = result.state\n",
        "  metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, metrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "IZtNgcQuUrMu",
        "outputId": "53c81a99-08b9-43e3-acae-dc5244fd324a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 90.0), ('loss', 0.6927795), ('accuracy', 0.53333336)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 90.0), ('loss', 0.6927426), ('accuracy', 0.53333336)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 90.0), ('loss', 0.6927064), ('accuracy', 0.53333336)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('num_examples', 90.0), ('loss', 0.69267094), ('accuracy', 0.53333336)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-2742602631d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mround_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_train_datasets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'round {:2d}, metrics={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     )\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     return self._async_runner.run_coro_and_return_result(\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/async_utils.py\u001b[0m in \u001b[0;36mrun_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;34m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_coroutine_threadsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawait_coro_and_return_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjiEzhwRTgJ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}