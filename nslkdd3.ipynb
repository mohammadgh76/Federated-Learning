{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOhcTVNBvAxHydVnu2X5lRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadgh76/Federated-Learning/blob/main/nslkdd3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iycl2TzR4DKw",
        "outputId": "24dc496e-aabb-4aa5-f113-053a7d2b2bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protocol_type\n",
            "service\n",
            "flag\n",
            "labels\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('x',\n",
              "              array([[-0.11024922, -0.12470616, -0.68678521, ...,  0.06997226,\n",
              "                      -0.2891034 , -0.22453241],\n",
              "                     [-0.11024922,  2.21931185,  0.78142753, ...,  2.36773734,\n",
              "                      -0.2891034 , -0.38763462],\n",
              "                     [-0.11024922, -0.12470616,  1.08730518, ..., -0.48019685,\n",
              "                      -0.2891034 , -0.38763462],\n",
              "                     ...,\n",
              "                     [-0.11024922, -0.12470616,  1.39318283, ..., -0.48019685,\n",
              "                      -0.2891034 , -0.35501418],\n",
              "                     [-0.11024922, -0.12470616, -0.0750299 , ..., -0.48019685,\n",
              "                      -0.2891034 , -0.38763462],\n",
              "                     [-0.11024922, -0.12470616, -0.68678521, ...,  0.49068981,\n",
              "                      -0.2891034 , -0.38763462]])),\n",
              "             ('y',\n",
              "              array([[1],\n",
              "                     [1],\n",
              "                     [0],\n",
              "                     ...,\n",
              "                     [1],\n",
              "                     [0],\n",
              "                     [1]]))])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import types\n",
        "from numpy.lib.arraysetops import unique\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "np.random.seed(0)\n",
        "# tff.federated_computation(lambda: \"dfkjsdjfjklfsd\")()\n",
        "\n",
        "trn = pd.read_csv(\"/content/kdd_train.csv\")\n",
        "trn.isnull().sum()\n",
        "trn.nunique()\n",
        "types = trn[\"labels\"].unique()\n",
        "types = types[1:]\n",
        "trn[\"labels\"].replace(to_replace=types,value=\"attacking\",inplace = True)\n",
        "c = len(trn.select_dtypes(include=[\"number\"]).columns)\n",
        "\n",
        "cols = ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
        "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
        "       'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
        "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
        "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
        "       'dst_host_srv_rerror_rate']\n",
        "\n",
        "for col in trn.select_dtypes(include=[\"object\"]):\n",
        "    print(col)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ['protocol_type','service','flag','labels']\n",
        "for i in cols:\n",
        "    en = LabelEncoder()\n",
        "    trn[i] = en.fit_transform(trn[i])\n",
        "\n",
        "\n",
        "corr_matrix = trn.corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
        "trn.drop(to_drop, axis=1, inplace=True)\n",
        "\n",
        "# numeric_feature_names = ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
        "#        'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
        "#        'root_shell', 'su_attempted',  'num_file_creations',\n",
        "#        'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "#        'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "#         'rerror_rate', 'same_srv_rate',\n",
        "#        'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "#        'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
        "#        'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "#        'dst_host_srv_diff_host_rate']\n",
        "# numeric_features = trn[numeric_feature_names]\n",
        "# numeric_features.head()\n",
        "trn.head(10)\n",
        "X_trn = trn.drop(['labels'] , axis = 1).values\n",
        "Y_trn = trn['labels'].values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_trn = scaler.fit_transform(X_trn)\n",
        "\n",
        "trn = tf.convert_to_tensor(trn)\n",
        "trn = tf.data.Dataset.from_tensors(trn)\n",
        "train_sample = tf.convert_to_tensor(X_trn)\n",
        "test_sample =  tf.convert_to_tensor(Y_trn)\n",
        "\n",
        "NUM_CLIENTS = 10\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 20\n",
        "SHUFFLE_BUFFER = 100\n",
        "PREFETCH_BUFFER = 10\n",
        "\n",
        "def preprocess(dataset):\n",
        "\n",
        "  def batch_format_fn(element):\n",
        "\n",
        "    return collections.OrderedDict(\n",
        "        x=tf.reshape(train_sample,[125973,-1]),\n",
        "        y=tf.reshape(test_sample,[125973,-1]))\n",
        "\n",
        "  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(\n",
        "      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "preprocessed_example_dataset = preprocess(trn)\n",
        "\n",
        "sample_batch = tf.nest.map_structure(lambda x: x.numpy(),\n",
        "                                     next(iter(preprocessed_example_dataset)))\n",
        "\n",
        "sample_batch\n"
      ]
    }
  ]
}